{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean_var_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate(list):\n",
    "    if (len(list) != 9):\n",
    "        raise ValueError(\"List must contain nine numbers.\")\n",
    "\n",
    "    ls = np.array(list)\n",
    "    print(ls)\n",
    "    #As of it is in the form of 3x3 matrix \n",
    "    mean_rows = [ls[[0,1,2]].mean(), ls[[3,4,5]].mean(), ls[[6,7,8]].mean()]\n",
    "    mean_colunms = [ls[[0,3,6]].mean(), ls[[1,4,7]].mean(), ls[[2,5,8]].mean()]\n",
    "    \n",
    "    var_rows = [ls[[0,1,2]].var(), ls[[3,4,5]].var(), ls[[6,7,8]].var()]\n",
    "    var_colunms = [ls[[0,3,6]].var(), ls[[1,4,7]].var(), ls[[2,5,8]].var()]\n",
    "\n",
    "    std_rows = [ls[[0,1,2]].std(), ls[[3,4,5]].std(), ls[[6,7,8]].std()]\n",
    "    std_colunms = [ls[[0,3,6]].std(), ls[[1,4,7]].std(), ls[[2,5,8]].std()]\n",
    "\n",
    "    max_rows = [ls[[0,1,2]].max(), ls[[3,4,5]].max(), ls[[6,7,8]].max()]\n",
    "    max_colunms = [ls[[0,3,6]].max(), ls[[1,4,7]].max(), ls[[2,5,8]].max()]\n",
    "\n",
    "    min_rows = [ls[[0,1,2]].min(), ls[[3,4,5]].min(), ls[[6,7,8]].min()]\n",
    "    min_colunms = [ls[[0,3,6]].min(), ls[[1,4,7]].min(), ls[[2,5,8]].min()]\n",
    "\n",
    "    sum_rows = [ls[[0,1,2]].sum(), ls[[3,4,5]].sum(), ls[[6,7,8]].sum()]\n",
    "    sum_colunms = [ls[[0,3,6]].sum(), ls[[1,4,7]].sum(), ls[[2,5,8]].sum()]\n",
    "\n",
    "    return { \n",
    "        'mean': [mean_colunms, mean_rows , ls.mean()], \n",
    "  'variance': [var_colunms, var_rows , ls.var()],\n",
    "  'standard deviation': [std_colunms, std_rows , ls.std()],\n",
    "  'max': [max_colunms, max_rows , ls.max()],\n",
    "  'min': [min_colunms, min_rows , ls.min()],\n",
    "  'sum': [sum_colunms, sum_rows , ls.sum()]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': [[3.0, 4.0, 5.0], [1.0, 4.0, 7.0], 4.0], 'variance': [[6.0, 6.0, 6.0], [0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 6.666666666666667], 'standard deviation': [[2.449489742783178, 2.449489742783178, 2.449489742783178], [0.816496580927726, 0.816496580927726, 0.816496580927726], 2.581988897471611], 'max': [[6, 7, 8], [2, 5, 8], 8], 'min': [[0, 1, 2], [0, 3, 6], 0], 'sum': [[9, 12, 15], [3, 12, 21], 36]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate(list):\n",
    "    if (len(list) != 9):\n",
    "        raise ValueError(\"List must contain nine numbers.\")\n",
    "\n",
    "    input_list = np.array(list)\n",
    "\n",
    "    # Reshape to 3x3 matrix\n",
    "    ls = np.array(input_list).reshape(3, 3)\n",
    "    print(ls)\n",
    "\n",
    "    #As of it is in the form of 3x3 matrix \n",
    "    mean_rows = [ls[[0,1,2]].mean(), ls[[3,4,5]].mean(), ls[[6,7,8]].mean()]\n",
    "    mean_colunms = [ls[[0,3,6]].mean(), ls[[1,4,7]].mean(), ls[[2,5,8]].mean()]\n",
    "    \n",
    "    var_rows = [ls[[0,1,2]].var(), ls[[3,4,5]].var(), ls[[6,7,8]].var()]\n",
    "    var_colunms = [ls[[0,3,6]].var(), ls[[1,4,7]].var(), ls[[2,5,8]].var()]\n",
    "\n",
    "    std_rows = [ls[[0,1,2]].std(), ls[[3,4,5]].std(), ls[[6,7,8]].std()]\n",
    "    std_colunms = [ls[[0,3,6]].std(), ls[[1,4,7]].std(), ls[[2,5,8]].std()]\n",
    "\n",
    "    max_rows = [ls[[0,1,2]].max(), ls[[3,4,5]].max(), ls[[6,7,8]].max()]\n",
    "    max_colunms = [ls[[0,3,6]].max(), ls[[1,4,7]].max(), ls[[2,5,8]].max()]\n",
    "\n",
    "    min_rows = [ls[[0,1,2]].min(), ls[[3,4,5]].min(), ls[[6,7,8]].min()]\n",
    "    min_colunms = [ls[[0,3,6]].min(), ls[[1,4,7]].min(), ls[[2,5,8]].min()]\n",
    "\n",
    "    sum_rows = [ls[[0,1,2]].sum(), ls[[3,4,5]].sum(), ls[[6,7,8]].sum()]\n",
    "    sum_colunms = [ls[[0,3,6]].sum(), ls[[1,4,7]].sum(), ls[[2,5,8]].sum()]\n",
    " \n",
    "    return { \n",
    "  'mean': [mean_colunms, mean_rows , ls.mean()], \n",
    "  'variance': [var_colunms, var_rows , ls.var()],\n",
    "  'standard deviation': [std_colunms, std_rows , ls.std()],\n",
    "  'max': [max_colunms, max_rows , ls.max()],\n",
    "  'min': [min_colunms, min_rows , ls.min()],\n",
    "  'sum': [sum_colunms, sum_rows , ls.sum()]\n",
    "}\n",
    "\n",
    "# This entrypoint file to be used in development. Start by reading README.md\n",
    "\n",
    "def main():\n",
    "    print(calculate([0,1,2,3,4,5,6,7,8]))\n",
    "\n",
    "# Run unit tests automatically\n",
    "main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_demographic_data(print_data=True):\n",
    "    # Read data from file\n",
    "    df = pd.read_csv('adult.data.csv')\n",
    "\n",
    "    # How many of each race are represented in this dataset? This should be a Pandas series with race names as the index labels.\n",
    "    race_count = df['race'].value_counts()\n",
    "\n",
    "    # What is the average age of men?\n",
    "    average_age_men = df[df['sex'] == 'Male']['age'].mean().round(1)\n",
    "\n",
    "    # What is the percentage of people who have a Bachelor's degree?\n",
    "    num_bachelors = len(df[df['education'] == \"Bachelors\"])\n",
    "    total_len = len(df['education'])\n",
    "    percentage_bachelors = round(num_bachelors / total_len * 100, 1)\n",
    "\n",
    "    # What percentage of people with advanced education (`Bachelors`, `Masters`, or `Doctorate`) make more than 50K?\n",
    "    # What percentage of people without advanced education make more than 50K?\n",
    "    higher_education = df[df['education'].isin([\"Bachelors\", \"Masters\", \"Doctorate\"])]\n",
    "    lower_education = df[~df['education'].isin([\"Bachelors\", \"Masters\", \"Doctorate\"])]\n",
    "\n",
    "    # Percentage with salary >50K\n",
    "    higher_education_rich = round(len(higher_education[higher_education['salary'] == \">50K\"]) / len(higher_education) * 100, 1)\n",
    "    lower_education_rich = round(len(lower_education[lower_education['salary'] == \">50K\"]) / len(lower_education) * 100, 1)\n",
    "\n",
    "    # What is the minimum number of hours a person works per week (hours-per-week feature)?\n",
    "    min_work_hours = df[\"hours-per-week\"].min()\n",
    "\n",
    "    # What percentage of the people who work the minimum number of hours per week have a salary of >50K?\n",
    "    num_min_workers = df[df[\"hours-per-week\"] == min_work_hours]\n",
    "    rich_percentage = round(len(num_min_workers[num_min_workers['salary'] == \">50K\"]) / len(num_min_workers) * 100, 1)\n",
    "\n",
    "    # What country has the highest percentage of people that earn >50K?\n",
    "    country_count = df['native-country'].value_counts()\n",
    "    country_rich_count = df[df[\"salary\"] == \">50K\"][\"native-country\"].value_counts()\n",
    "\n",
    "    highest_earning_country = (country_rich_count / country_count * 100).idxmax()\n",
    "    highest_earning_country_percentage = round((country_rich_count / country_count * 100).max(), 1)\n",
    "\n",
    "    # Identify the most popular occupation for those who earn >50K in India.\n",
    "    people_of_india = df[(df[\"native-country\"] == \"India\") & (df[\"salary\"] == \">50K\")]\n",
    "    occupation_count = people_of_india[\"occupation\"].value_counts()\n",
    "    top_IN_occupation = occupation_count.idxmax()\n",
    "\n",
    "    # DO NOT MODIFY BELOW THIS LINE\n",
    "    if print_data:\n",
    "        print(\"Number of each race:\\n\", race_count)\n",
    "        print(\"Average age of men:\", average_age_men)\n",
    "        print(f\"Percentage with Bachelors degrees: {percentage_bachelors}%\")\n",
    "        print(f\"Percentage with higher education that earn >50K: {higher_education_rich}%\")\n",
    "        print(f\"Percentage without higher education that earn >50K: {lower_education_rich}%\")\n",
    "        print(f\"Min work time: {min_work_hours} hours/week\")\n",
    "        print(f\"Percentage of rich among those who work fewest hours: {rich_percentage}%\")\n",
    "        print(\"Country with highest percentage of rich:\", highest_earning_country)\n",
    "        print(f\"Highest percentage of rich people in country: {highest_earning_country_percentage}%\")\n",
    "        print(\"Top occupations in India:\", top_IN_occupation)\n",
    "\n",
    "    return {\n",
    "        'race_count': race_count,\n",
    "        'average_age_men': average_age_men,\n",
    "        'percentage_bachelors': percentage_bachelors,\n",
    "        'higher_education_rich': higher_education_rich,\n",
    "        'lower_education_rich': lower_education_rich,\n",
    "        'min_work_hours': min_work_hours,\n",
    "        'rich_percentage': rich_percentage,\n",
    "        'highest_earning_country': highest_earning_country,\n",
    "        'highest_earning_country_percentage': highest_earning_country_percentage,\n",
    "        'top_IN_occupation': top_IN_occupation\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This entrypoint file to be used in development. Start by reading README.md\n",
    "import demographic_data_analyzer\n",
    "from unittest import main\n",
    "\n",
    "# Test your function by calling it here\n",
    "demographic_data_analyzer.calculate_demographic_data()\n",
    "\n",
    "# Run unit tests automatically\n",
    "main(module='test_module', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"medical_examination.csv\")\n",
    "\n",
    "# 2. Calculate overweight column\n",
    "df['overweight'] = ((df[\"weight\"] / ((df['height'] / 100) ** 2)) > 25).astype(int)\n",
    "\n",
    "# 3. Normalize cholesterol and gluc values\n",
    "df[\"cholesterol\"] = df['cholesterol'].apply(lambda x: 0 if x == 1 else 1)\n",
    "df['gluc'] = df['gluc'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# 4. Function to draw categorical plot\n",
    "def draw_cat_plot():\n",
    "    # 5. Melt data\n",
    "    df_cat = pd.melt(df, id_vars=['cardio'], value_vars=['cholesterol', 'gluc', 'smoke', 'alco', 'active', 'overweight'])\n",
    "\n",
    "    # 6. Group and count data\n",
    "    df_cat['total'] = 1\n",
    "    df_cat = df_cat.groupby(['cardio', 'variable', 'value'], as_index=False).count()\n",
    "\n",
    "    # 7 & 8. Draw the catplot\n",
    "    fig = sns.catplot(x=\"variable\", y=\"total\", data=df_cat, hue='value', kind='bar', col='cardio').fig\n",
    "\n",
    "    # 9. Save the figure\n",
    "    fig.savefig('catplot.png')\n",
    "    return fig\n",
    "\n",
    "# 10. Function to draw heatmap\n",
    "def draw_heat_map():\n",
    "    # 11. Clean the data\n",
    "    df_heat = df[\n",
    "        (df['ap_lo'] <= df['ap_hi']) &\n",
    "        (df['height'] >= df['height'].quantile(0.025)) &\n",
    "        (df['height'] <= df['height'].quantile(0.975)) &\n",
    "        (df['weight'] >= df['weight'].quantile(0.025)) &\n",
    "        (df['weight'] <= df['weight'].quantile(0.975))\n",
    "    ]\n",
    "\n",
    "    # 12. Calculate the correlation matrix\n",
    "    corr = df_heat.corr(method=\"pearson\")\n",
    "\n",
    "    # 13. Generate a mask for the upper triangle\n",
    "    mask = np.triu(corr)\n",
    "\n",
    "    # 14 & 15. Set up the matplotlib figure and draw the heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    sns.heatmap(corr, linewidths=1, annot=True, square=True, mask=mask, fmt='.1f',\n",
    "                center=0, cbar_kws={\"shrink\": 0.5})\n",
    "\n",
    "    # 16. Save the figure\n",
    "    fig.savefig('heatmap.png')\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# This entrypoint file to be used in development. Start by reading README.md\n",
    "import medical_data_visualizer\n",
    "from unittest import main\n",
    "\n",
    "# Test your function by calling it here\n",
    "medical_data_visualizer.draw_cat_plot()\n",
    "medical_data_visualizer.draw_heat_map()\n",
    "\n",
    "# Run unit tests automatically\n",
    "main(module='test_module', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Project 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"fcc-forum-pageviews.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "\n",
    "# Clean data by removing the top 2.5% and bottom 2.5% of page views\n",
    "df = df[(df['value'] >= df['value'].quantile(0.025)) & (df['value'] <= df['value'].quantile(0.975))]\n",
    "\n",
    "def draw_line_plot():\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(df.index, df['value'], color='r', linewidth=1)\n",
    "\n",
    "    ax.set_title(\"Daily freeCodeCamp Forum Page Views 5/2016-12/2019\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Page Views\")\n",
    "\n",
    "    fig.savefig('line_plot.png')\n",
    "    return fig\n",
    "\n",
    "def draw_bar_plot():\n",
    "    df_bar = df.copy()\n",
    "    df_bar['year'] = df.index.year\n",
    "    df_bar['month'] = df.index.month\n",
    "    df_bar = df_bar.groupby(['year', 'month'])['value'].mean().unstack()\n",
    "\n",
    "    # Create the bar plot\n",
    "    fig = df_bar.plot(kind='bar', figsize=(12, 6), legend=True).figure\n",
    "    plt.xlabel(\"Years\")  # Set the x-axis label to \"Years\"\n",
    "    plt.ylabel(\"Average Page Views\")\n",
    "\n",
    "    # Set the legend title and labels correctly to full month names\n",
    "    plt.legend(title=\"Months\", labels=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    fig.savefig('bar_plot.png')\n",
    "    return fig\n",
    "\n",
    "def draw_box_plot():\n",
    "    df_box = df.copy()\n",
    "    df_box.reset_index(inplace=True)\n",
    "    df_box['year'] = df_box['date'].dt.year\n",
    "    df_box['month'] = df_box['date'].dt.strftime('%b')\n",
    "\n",
    "    # Create a month number for sorting\n",
    "    df_box['month_num'] = df_box['date'].dt.month \n",
    "    df_box = df_box.sort_values(\"month_num\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Year-wise box plot\n",
    "    sns.boxplot(x='year', y='value', data=df_box, ax=axes[0])\n",
    "    axes[0].set_title(\"Year-wise Box Plot (Trend)\")\n",
    "    axes[0].set_xlabel(\"Year\")\n",
    "    axes[0].set_ylabel(\"Page Views\")\n",
    "\n",
    "    # Month-wise box plot\n",
    "    sns.boxplot(x='month', y='value', data=df_box, ax=axes[1], order=[\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])\n",
    "    axes[1].set_title(\"Month-wise Box Plot (Seasonality)\")\n",
    "    axes[1].set_xlabel(\"Month\")\n",
    "    axes[1].set_ylabel(\"Page Views\")\n",
    "\n",
    "    fig.savefig('box_plot.png')\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# This entrypoint file to be used in development. Start by reading README.md\n",
    "import time_series_visualizer\n",
    "from unittest import main\n",
    "\n",
    "# Test your function by calling it here\n",
    "time_series_visualizer.draw_line_plot()\n",
    "time_series_visualizer.draw_bar_plot()\n",
    "time_series_visualizer.draw_box_plot()\n",
    "\n",
    "# Run unit tests automatically\n",
    "main(module='test_module', exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
